diff --git a/cmake/CMakeLists.txt b/cmake/CMakeLists.txt
index 8edbb6ad6..f0016676c 100644
--- a/cmake/CMakeLists.txt
+++ b/cmake/CMakeLists.txt
@@ -39,12 +39,7 @@ include(CMakeDependentOption)
 include(FetchContent)
 include(CheckFunctionExists)
 
-# TODO: update this once all system adapt c++20
-if(CMAKE_SYSTEM_NAME STREQUAL "Darwin")
-set(CMAKE_CXX_STANDARD 20)
-else()
 set(CMAKE_CXX_STANDARD 17)
-endif()
 
 set_property(GLOBAL PROPERTY USE_FOLDERS ON)
 # NOTE: POSITION INDEPENDENT CODE hurts performance, and it only make sense on POSIX systems
@@ -1494,7 +1489,7 @@ if (onnxruntime_USE_DML)
     message(FATAL_ERROR "The DirectML execution provider is only supported when building for Windows.")
   endif()
 
-  include(dml)
+  #include(dml)
 endif()
 
 if (onnxruntime_ENABLE_TRAINING_APIS)
diff --git a/cmake/external/abseil-cpp.cmake b/cmake/external/abseil-cpp.cmake
index 57cfbee46..529f8dfa5 100644
--- a/cmake/external/abseil-cpp.cmake
+++ b/cmake/external/abseil-cpp.cmake
@@ -1,47 +1,7 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # Licensed under the MIT License.
 
-include(FetchContent)
-
-# Pass to build
-set(ABSL_PROPAGATE_CXX_STD 1)
-set(BUILD_TESTING 0)
-set(ABSL_BUILD_TESTING OFF)
-set(ABSL_BUILD_TEST_HELPERS OFF)
-set(ABSL_USE_EXTERNAL_GOOGLETEST ON)
-if(Patch_FOUND AND WIN32)
-  set(ABSL_PATCH_COMMAND ${Patch_EXECUTABLE} --binary --ignore-whitespace -p1 < ${PROJECT_SOURCE_DIR}/patches/abseil/absl_windows.patch)
-else()
-  set(ABSL_PATCH_COMMAND "")
-endif()
-if(WIN32 AND NOT Patch_FOUND)
-  #see https://github.com/google/re2/issues/425 and https://github.com/google/re2/issues/436
-  set(ABSL_ENABLE_INSTALL ON)
-endif()
-# NB! Advancing Abseil version changes its internal namespace,
-# currently absl::lts_20240116 which affects abseil-cpp.natvis debugger
-# visualization file, that must be adjusted accordingly, unless we eliminate
-# that namespace at build time.
-FetchContent_Declare(
-    abseil_cpp
-    URL ${DEP_URL_abseil_cpp}
-    URL_HASH SHA1=${DEP_SHA1_abseil_cpp}
-    PATCH_COMMAND ${ABSL_PATCH_COMMAND}
-    FIND_PACKAGE_ARGS NAMES absl
-)
-
-onnxruntime_fetchcontent_makeavailable(abseil_cpp)
-FetchContent_GetProperties(abseil_cpp)
-set(ABSEIL_SOURCE_DIR ${abseil_cpp_SOURCE_DIR})
-message(STATUS "Abseil source dir:" ${ABSEIL_SOURCE_DIR})
-
-if (GDK_PLATFORM)
-  # Abseil considers any partition that is NOT in the WINAPI_PARTITION_APP a viable platform
-  # for Win32 symbolize code (which depends on dbghelp.lib); this logic should really be flipped
-  # to only include partitions that are known to support it (e.g. DESKTOP). As a workaround we
-  # tell Abseil to pretend we're building an APP.
-  target_compile_definitions(absl_symbolize PRIVATE WINAPI_FAMILY=WINAPI_FAMILY_DESKTOP_APP)
-endif()
+find_package(absl REQUIRED)
 
 # TODO: since multiple ORT's dependencies depend on Abseil, the list below would vary from version to version.
 # We'd better to not manually manage the list.
diff --git a/cmake/external/eigen.cmake b/cmake/external/eigen.cmake
index b123adb62..3d8fa153f 100644
--- a/cmake/external/eigen.cmake
+++ b/cmake/external/eigen.cmake
@@ -1,7 +1,6 @@
 if (onnxruntime_USE_PREINSTALLED_EIGEN)
-    add_library(eigen INTERFACE)
-    file(TO_CMAKE_PATH ${eigen_SOURCE_PATH} eigen_INCLUDE_DIRS)
-    target_include_directories(eigen INTERFACE ${eigen_INCLUDE_DIRS})
+    find_package(Eigen3 CONFIG REQUIRED)
+    add_library(eigen ALIAS Eigen3::Eigen)
 else ()
     FetchContent_Declare(
         eigen
diff --git a/cmake/external/onnxruntime_external_deps.cmake b/cmake/external/onnxruntime_external_deps.cmake
index 8839dbc8f..0c53756bc 100644
--- a/cmake/external/onnxruntime_external_deps.cmake
+++ b/cmake/external/onnxruntime_external_deps.cmake
@@ -85,7 +85,7 @@ if (NOT WIN32)
     google_nsync
     URL ${DEP_URL_google_nsync}
     URL_HASH SHA1=${DEP_SHA1_google_nsync}
-    FIND_PACKAGE_ARGS NAMES nsync
+    FIND_PACKAGE_ARGS NAMES unofficial-nsync
     )
 endif()
 list(APPEND CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/external)
@@ -94,6 +94,7 @@ FetchContent_Declare(
       mimalloc
       URL ${DEP_URL_mimalloc}
       URL_HASH SHA1=${DEP_SHA1_mimalloc}
+      FIND_PACKAGE_ARGS NAMES mimalloc
 )
 
 
@@ -200,7 +201,7 @@ FetchContent_Declare(
   URL ${DEP_URL_protobuf}
   URL_HASH SHA1=${DEP_SHA1_protobuf}
   PATCH_COMMAND ${ONNXRUNTIME_PROTOBUF_PATCH_COMMAND}
-  FIND_PACKAGE_ARGS 3.21.12 NAMES Protobuf
+  FIND_PACKAGE_ARGS 3.21.12 NAMES Protobuf CONFIGS
 )
 
 set(protobuf_BUILD_TESTS OFF CACHE BOOL "Build protobuf tests" FORCE)
@@ -233,11 +234,17 @@ FetchContent_Declare(
 )
 onnxruntime_fetchcontent_makeavailable(date)
 
-FetchContent_Declare(
-  mp11
-  URL ${DEP_URL_mp11}
-  URL_HASH SHA1=${DEP_SHA1_mp11}
-)
+
+# BEGIN vcpkg-specific
+if(NOT TARGET date_interface)
+  # headers installed by vcpkg
+  add_library(date_interface INTERFACE)
+endif()
+
+# mp11 is a header-only library installed without CMake support.
+add_library(mp11 INTERFACE)
+add_library(Boost::mp11 ALIAS mp11)
+# END vcpkg-specific
 
 set(JSON_BuildTests OFF CACHE INTERNAL "")
 set(JSON_Install OFF CACHE INTERNAL "")
@@ -287,15 +294,8 @@ endif()
 # xnnpack depends on clog
 # Android build should use the system's log library instead of clog
 if ((CPUINFO_SUPPORTED OR onnxruntime_USE_XNNPACK) AND NOT ANDROID)
-  set(CLOG_BUILD_TESTS OFF CACHE BOOL "" FORCE)
-  FetchContent_Declare(
-    pytorch_clog
-    URL ${DEP_URL_pytorch_cpuinfo}
-    URL_HASH SHA1=${DEP_SHA1_pytorch_cpuinfo}
-    SOURCE_SUBDIR deps/clog
-  )
-  set(ONNXRUNTIME_CLOG_PROJ pytorch_clog)
-  set(ONNXRUNTIME_CLOG_TARGET_NAME clog)
+  find_package(cpuinfo CONFIG REQUIRED)
+  set(ONNXRUNTIME_CLOG_TARGET_NAME cpuinfo::clog)
 endif()
 
 if (CPUINFO_SUPPORTED)
@@ -324,15 +324,11 @@ if (CPUINFO_SUPPORTED)
         PATCH_COMMAND ${Patch_EXECUTABLE} -p1 < ${PROJECT_SOURCE_DIR}/patches/cpuinfo/9bb12d342fd9479679d505d93a478a6f9cd50a47.patch
         FIND_PACKAGE_ARGS NAMES cpuinfo
       )
+      set(ONNXRUNTIME_CPUINFO_PROJ pytorch_cpuinfo)
   else()
-      FetchContent_Declare(
-        pytorch_cpuinfo
-        URL ${DEP_URL_pytorch_cpuinfo}
-        URL_HASH SHA1=${DEP_SHA1_pytorch_cpuinfo}
-        FIND_PACKAGE_ARGS NAMES cpuinfo
-      )
+      find_package(cpuinfo CONFIG REQUIRED)
+      add_library(cpuinfo ALIAS cpuinfo::cpuinfo)
   endif()
-  set(ONNXRUNTIME_CPUINFO_PROJ pytorch_cpuinfo)
 endif()
 
 
@@ -341,12 +337,10 @@ if (onnxruntime_BUILD_BENCHMARKS)
 endif()
 
 if (NOT WIN32)
-  #nsync tests failed on Mac Build
-  set(NSYNC_ENABLE_TESTS OFF CACHE BOOL "" FORCE)
-  onnxruntime_fetchcontent_makeavailable(google_nsync)
-  if (google_nsync_SOURCE_DIR)
-    add_library(nsync::nsync_cpp ALIAS nsync_cpp)
-    target_include_directories(nsync_cpp PUBLIC ${google_nsync_SOURCE_DIR}/public)
+  # vcpkg-specific
+  find_package(unofficial-nsync CONFIGS REQUIRED)
+  if(TARGET unofficial::nsync::nsync_cpp)
+    add_library(nsync::nsync_cpp ALIAS unofficial::nsync::nsync_cpp)
   endif()
 endif()
 
@@ -380,7 +374,7 @@ onnxruntime_fetchcontent_makeavailable(utf8_range)
 # protobuf's cmake/utf8_range.cmake has the following line
 include_directories(${utf8_range_SOURCE_DIR})
 
-onnxruntime_fetchcontent_makeavailable(Protobuf nlohmann_json mp11 re2 GSL flatbuffers ${ONNXRUNTIME_CPUINFO_PROJ} ${ONNXRUNTIME_CLOG_PROJ})
+onnxruntime_fetchcontent_makeavailable(Protobuf nlohmann_json re2 GSL flatbuffers ${ONNXRUNTIME_CPUINFO_PROJ})
 if(NOT flatbuffers_FOUND)
   if(NOT TARGET flatbuffers::flatbuffers)
     add_library(flatbuffers::flatbuffers ALIAS flatbuffers)
@@ -484,7 +478,9 @@ include(eigen)
 include(wil)
 
 if (NOT onnxruntime_MINIMAL_BUILD)
-    onnxruntime_fetchcontent_makeavailable(onnx)
+  find_package(ONNX CONFIGS REQUIRED)
+  add_library(onnx ALIAS ONNX::onnx)
+  add_library(onnx_proto ALIAS ONNX::onnx_proto)
 else()
   include(onnx_minimal)
 endif()
@@ -522,11 +518,6 @@ set(onnxruntime_EXTERNAL_LIBRARIES ${onnxruntime_EXTERNAL_LIBRARIES_XNNPACK} ${W
 # The other libs do not have the problem. All the sources are already there. We can compile them in any order.
 set(onnxruntime_EXTERNAL_DEPENDENCIES onnx_proto flatbuffers::flatbuffers)
 
-target_compile_definitions(onnx PUBLIC $<TARGET_PROPERTY:onnx_proto,INTERFACE_COMPILE_DEFINITIONS> PRIVATE "__ONNX_DISABLE_STATIC_REGISTRATION")
-if (NOT onnxruntime_USE_FULL_PROTOBUF)
-  target_compile_definitions(onnx PUBLIC "__ONNX_NO_DOC_STRINGS")
-endif()
-
 if (onnxruntime_RUN_ONNX_TESTS)
   add_definitions(-DORT_RUN_EXTERNAL_ONNX_TESTS)
 endif()
@@ -557,16 +548,6 @@ if(onnxruntime_ENABLE_TRAINING OR (onnxruntime_ENABLE_TRAINING_APIS AND onnxrunt
   onnxruntime_fetchcontent_makeavailable(cxxopts)
 endif()
 
-if (onnxruntime_USE_COREML)
-  FetchContent_Declare(
-    coremltools
-    URL ${DEP_URL_coremltools}
-    URL_HASH SHA1=${DEP_SHA1_coremltools}
-    PATCH_COMMAND ${Patch_EXECUTABLE} --binary --ignore-whitespace -p1 < ${PROJECT_SOURCE_DIR}/patches/coremltools/crossplatformbuild.patch
-  )
-  # we don't build directly so use Populate. selected files are built from onnxruntime_providers_coreml.cmake
-  FetchContent_Populate(coremltools)
-endif()
 
 message("Finished fetching external dependencies")
 
diff --git a/cmake/onnxruntime_providers_coreml.cmake b/cmake/onnxruntime_providers_coreml.cmake
index 0aa25a221..e46e6f44a 100644
--- a/cmake/onnxruntime_providers_coreml.cmake
+++ b/cmake/onnxruntime_providers_coreml.cmake
@@ -9,27 +9,14 @@ add_compile_definitions(USE_COREML=1)
 
 # Check if we can build the coremltools code for creating an mlpackage with an mlprogram.
 # The coremltools source requires std::filesystem::path which is only available from iOS 13 on.
-set(_enable_ML_PROGRAM ON)
-if (IOS AND CMAKE_OSX_DEPLOYMENT_TARGET VERSION_LESS 13.0)
-  message(WARNING "CoreML ML Program is not supported on iOS < 13.0. Excluding ML Program support from build.")
-  set(_enable_ML_PROGRAM OFF)
-elseif(LINUX)
-  # uuid-dev is required. we don't bother installing on CIs as it's really for manual developer testing.
-  find_library(LibUUID_LIBRARY NAMES uuid)
-  find_path(LibUUID_INCLUDE_DIR NAMES uuid/uuid.h)
-  if (NOT LibUUID_INCLUDE_DIR)
-    message(STATUS "uuid/uuid.h was not found as is required for ML Program support. "
-                    "Run `sudo apt install uuid-dev` if you need to test ML Program related CoreML EP code. ")
-    set(_enable_ML_PROGRAM OFF)
-  endif()
-endif()
+set(_enable_ML_PROGRAM OFF)
 
 if (_enable_ML_PROGRAM)
   add_compile_definitions(COREML_ENABLE_MLPROGRAM=1)
 endif()
 
 # Compile CoreML proto definition to ${CMAKE_CURRENT_BINARY_DIR}/coreml_proto
-set(COREML_PROTO_ROOT ${coremltools_SOURCE_DIR}/mlmodel/format)
+set(COREML_PROTO_ROOT ${CMAKE_CURRENT_LIST_DIR}/external/coremltools/mlmodel/format)
 file(GLOB coreml_proto_srcs "${COREML_PROTO_ROOT}/*.proto")
 
 onnxruntime_add_static_library(coreml_proto ${coreml_proto_srcs})
diff --git a/cmake/onnxruntime_providers_dml.cmake b/cmake/onnxruntime_providers_dml.cmake
index 439be882d..dfc061f42 100644
--- a/cmake/onnxruntime_providers_dml.cmake
+++ b/cmake/onnxruntime_providers_dml.cmake
@@ -21,32 +21,9 @@
     target_compile_options(onnxruntime_providers_dml PRIVATE "/wd4100" "/wd4238" "/wd4189" "/wd4702")
   endif()
 
-  if (NOT onnxruntime_USE_CUSTOM_DIRECTML)
-    foreach(file "DirectML.dll" "DirectML.pdb" "DirectML.Debug.dll" "DirectML.Debug.pdb")
-      add_custom_command(TARGET onnxruntime_providers_dml
-        POST_BUILD
-        COMMAND ${CMAKE_COMMAND} -E copy_if_different
-          "${DML_PACKAGE_DIR}/bin/${onnxruntime_target_platform}-win/${file}" $<TARGET_FILE_DIR:onnxruntime_providers_dml>)
-    endforeach()
-  endif()
-
   function(target_add_dml target)
-    if (onnxruntime_USE_CUSTOM_DIRECTML)
-      if (dml_EXTERNAL_PROJECT)
-        # Internal build of DirectML: link against the "DirectML" target.
-        target_link_libraries(${target} PRIVATE DirectML)
-      else()
-        if (dml_LIB_DIR)
-          target_link_libraries(${target} PRIVATE ${dml_LIB_DIR}/DirectML.lib)
-        else()
-          target_link_libraries(${target} PRIVATE DirectML)
-        endif()
-      endif()
-    else()
-      add_dependencies(${target} RESTORE_PACKAGES)
-      target_link_libraries(${target} PRIVATE "${DML_PACKAGE_DIR}/bin/${onnxruntime_target_platform}-win/DirectML.lib")
-        target_compile_definitions(${target} PRIVATE DML_TARGET_VERSION_USE_LATEST)
-    endif()
+    # use directml.lib from Windows SDK
+    target_link_libraries(${target} PRIVATE DirectML)
   endfunction()
 
   target_add_dml(onnxruntime_providers_dml)
